;---------------------------- CONFIG START ------------------------------------


; -----------------------------------------------------------------------------
; A sample config file contents for a scrape-jobs.ini
; -----------------------------------------------------------------------------


; -----------------------------------------------------------------------------
; The main focus is the upload params, since they are needed for all sites
[DEFAULT]
; The name of the 'Spreadsheet' where the results are to be uploaded
upload_spreadsheet_name = jobs_stats_data
; full path to the secrets.json that is needed for google authentication
upload_spreadsheet_json = Replace with path to secrets.json file.
; zero-based index of the upload target 'Worksheet'
upload_worksheet_index = 0
; Format for the 'scraped' timestamp (configurable per-site)
scraped_timestamp_format = %Y-%m-%d %H:%M
; Format for the job 'posted' timestamp (configurable per-site)
posted_timestamp_format = %Y-%m-%d %H:%M
; Example format (greatest precision): "%Y-%m-%d %H:%M:%S:%f"
; Will produce stamp like "2019-09-05 00:13:32:165962"
; -----------------------------------------------------------------------------


; -----------------------------------------------------------------------------
; This section provides the config needed to scrape seek.com.au
[seek.com.au]
; If the query contains quotes, define it as string (e.g. '"this" OR "that"')
what = Replace with search query
; Set the value to one that appears in the actual UI autocomplete items
where = All Sydney NSW
; Jobs posted in the past n-days will be collected
days = 3
; Collected results 'scrape stamp' and the 'post stamp' will be in this tz
; It should be python compatible (e.g in format Continent/City)
timezone = Australia/Sydney
; Index of target 'Worksheet' - it's good to have separate worksheet per site,
; because the collected columns of each site differ
upload_worksheet_index = 0
; For the seek.com.au 'Worksheet' set the columns (first row cells values) to:
; Scraped, Posted, Location, Title, Company, Classification, URL, Salary
; Format for the 'scraped' timestamp for seek.com.au results
scraped_timestamp_format = %Y-%m-%d %H:%M
; Format for the job 'posted' timestamp for seek.com.au results
posted_timestamp_format = %Y-%m-%d %H:00
; -----------------------------------------------------------------------------


; -----------------------------------------------------------------------------
; This section provides the config for scraping linkedin.com
[linkedin.com]
; Set the keywords value to one that matches a value in actual UI's autocomplete
; Otherwise the search may not yield any results.
keywords = Replace with search query
; Set the location value to one that matches a value in actual UI's autocomplete
; Otherwise the search may not yield any results.
location = Sydney, New South Wales, Australia
; Set a date posted filter to be applied after the search keywords and location
; valid values: [ Past 24 hours | Past Week | Past Month | Any Time ]
date_posted = Past Month
; Jobs posted in the past n-days will be collected
days = 2
; Collected results 'scrape stamp' and the 'post stamp' will be in this tz
; It should be python compatible (e.g in format Continent/City)
timezone = Australia/Sydney
; Index of target 'Worksheet' - it's good to have separate worksheet per site,
; because the collected columns of each site differ
upload_worksheet_index = 1
; For linkedin.com 'Worksheet' set the columns (first row cells values) to:
; Scraped, Posted, Location, Title, Company, URL
; Format for the 'scraped' timestamp for linkedin.com results
scraped_timestamp_format = %Y-%m-%d %H:%M
; Format for the job 'posted' timestamp for linkedin.com results
posted_timestamp_format = %Y-%m-%d
; -----------------------------------------------------------------------------
;------------------------------ CONFIG END ------------------------------------