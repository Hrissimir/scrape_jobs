[metadata]
name = scrape_jobs
description = CLI jobs scraper targeting multiple sites
author = Hrissimir
author-email = hrisimir.dakov@gmail.com
license = mit
long-description = file: README.rst
long-description-content-type = text/x-rst; charset=UTF-8
url = https://github.com/Hrissimir/scrape_jobs
project-urls =
    Code = https://github.com/Hrissimir/scrape_jobs

platforms = any
classifiers =
    Development Status :: 4 - Beta
    Programming Language :: Python

[options]
zip_safe = False
packages = find:
include_package_data = True
package_dir =
    =src
# DON'T CHANGE THE FOLLOWING LINE! IT WILL BE UPDATED BY PYSCAFFOLD!
setup_requires = pyscaffold>=3.2a0,<3.3a0

# `pip install scrape-jobs`
install_requires =
    hed_utils==4.1.0

python_requires = >=3.6

[options.packages.find]
where = src
exclude =
    tests

[options.extras_require]
# `pip install scrape-jobs[testing]`
testing =
    coverage==5.0
    flake8==3.7.9
    pylint==2.4.4
    pytest==5.3.2
    pytest-cov==2.8.1
    pyscaffold[all]==3.2.3
    twine==3.1.1

[options.entry_points]
console_scripts =
    scrape-jobs = scrape_jobs.cli.scrape:run
    scrape-jobs-init-config =  scrape_jobs.cli.init_config:run

[test]
addopts = --verbose
extras = True

[tool:pytest]
addopts =
    --cov scrape_jobs
    --cov-report term-missing
    --cov-report html
    --verbose

norecursedirs =
    dist
    build
    .tox

testpaths = tests

[aliases]
dists = clean build sdist --format=zip bdist_wheel


[bdist_wheel]
universal = 0

[build_sphinx]
source_dir = docs
build_dir = build/sphinx

[devpi:upload]
no-vcs = 1
formats = bdist_wheel

[flake8]
# Some sane defaults for the code style checker flake8
exclude =
    .tox
    build
    dist
    .eggs
    docs/conf.py

[pyscaffold]
# PyScaffold's parameters when the project was created.
# This will be used when updating. Do not change!
version = 3.2.1
package = scrape_jobs
